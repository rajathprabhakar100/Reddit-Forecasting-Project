---
title: "Complete Analysis"
author: "Rajath Prabhakar"
date: "2024-03-19"
output: html_document
---

```{r}
library(here)
```
Start with the merged Reddit files. Then apply the user-generated function process_reddit_files() to the Reddit files. This function outputs a daily 7 day rolling average of each variable. 

##Using the Raw Data
#Skip chunks at line 15 and line 33 if you would not like to wait forever for the chunks to run


```{r}
source(here("Functions", "03 - process_reddit_files().R"))
```

```{r}
#process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "Atlanta_clean.csv")
#process_reddit_files(folder_path = "Source Data/02 - Clean Data", filename = "Austin_clean.csv")
#process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "boston_clean.csv")
#process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "chicago_clean.csv")
#process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "houston_clean.csv")
#process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "LosAngeles_clean.csv")
#process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "nashville_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "nyc_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "orlando_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "philadelphia_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "Portland_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "phoenix_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "raleigh_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "sandiego_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "sanfrancisco_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "Seattle_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "StLouis_clean.csv")
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "washingtondc_clean.csv")
```

For example:
process_reddit_files(folder_path = "Source Data/02 - Clean Data/", filename = "Atlanta_clean.csv")

For cities with multiple subreddits, namely New York City and Minneapolis, combine the data from those subreddits first, then manually apply the contents of the process_reddit_files() function to it.

New York City

```{r}
nyc <- fread("Source Data/01 - Raw/merged_nyc.csv")
nyc1 <- fread("Source Data/01 - Raw/merged_newyorkcity.csv")

nyc2 <- bind_rows(nyc, nyc1)

nyc2 <- nyc2 %>% 
  mutate(Date = as_datetime(created_utc, tz = "America/Chicago") %>% 
           as_date()) %>%
  select(-created_utc) %>% 
  select(author, Date, everything()) %>% 
  mutate(author = replace(author, author %in% c("[deleted]", "AutoModerator"), NA)) %>% 
  select(-c(author, subreddit, parent_id, score, id, Segment)) %>% 
  group_by(Date) %>% 
  summarize_all(mean, na.rm = T) %>% 
  rename_with(~paste0("mean_", .), -Date) %>% 
  mutate_at(vars(starts_with("mean_")),
            list(~rollmean(., k = 7, fill = NA, align = "right"))) %>% 
  arrange(Date) %>% 
  filter(Date >= "2019-01-01")

fwrite(nyc2, "Source Data/03 - Daily Data/nyc_daily.csv")
```

Minneapolis

```{r}
library(data.table)
library(tidyverse)
library(zoo)
min1 <- fread("Source Data/01 - Raw/merged_minneapolis.csv")
min2 <- fread("Source Data/01 - Raw/merged_twincities.csv")

min3 <- bind_rows(min1, min2) %>% 
  mutate(Date = as_datetime(created_utc, tz = "America/Chicago") %>% 
           as_date()) %>%
  select(-created_utc) %>% 
  select(author, Date, everything()) %>% 
  mutate(author = replace(author, author %in% c("[deleted]", "AutoModerator"), NA)) %>% 
  select(-c(author, subreddit, parent_id, score, id, Segment)) %>% 
  group_by(Date) %>% 
  summarize_all(mean, na.rm = T) %>% 
  rename_with(~paste0("mean_", .), -Date) %>% 
  mutate_at(vars(starts_with("mean_")),
            list(~rollmean(., k = 7, fill = NA, align = "right"))) %>% 
  arrange(Date) %>% 
  filter(Date >= "2019-01-01")
  
fwrite(min3, "Source Data/03 - Daily Data/minneapolis_daily.csv")
```

```{r}
source(here("Functions", "04 - ccf_city_case_files().R"))
```
```{r}
file_names <- list.files("Source Data/Daily Data", pattern = "*_daily.csv", full.names = TRUE)
for (file in file_names) {
  file_name <- file.path(file)
  data <- fread(file_name) %>%
    #mutate(Date = as.Date(Date)) %>% 
    filter(Date >= "2019-01-20") %>% 
    mutate(week = floor_date(Date, "week")) %>% 
    group_by(week) %>% 
    summarize(across(-Date, mean, na.rm = T))
  city_name <- sub(".*Source Data/Daily Data/(.*)_daily\\.csv", "\\1", file)
  city_name <- trimws(city_name)
  output_filename <- paste0("Source Data/Weekly Data/", city_name, "_weekly.csv")
  fwrite(data, output_filename)
  
}
```

```{r}
source(here("Results", "R codes", "Code for combined_data.R"))
```

Create a combined data frame using Max ACF and Lag where Max ACF takes place
```{r}
combo
```


```{r}
source(here("Results/R codes", "AverageCityRank.R"))
```
```{r}
rank_avg
```

mean_illness has the highest average rank for positive lags, while mean_analytic has the highest average rank for negative lags. 

```{r}
source(here("Results/R codes", "Code for table_of_average_acf_lag.R"))
```

```{r}
table1 %>% arrange(Average_ACF_positive)
```

mean_illness has the highest correlation with Covid cases, and has an average lag of about 14 days. 

```{r}
top12variables <- table1 %>%
  arrange(-Average_ACF_positive) %>%
  slice(1:12) %>%
  pull(Variable) %>%
  as.character()

top_12 <- combined %>% 
  filter(Lag > 0 & Variable %in% top12variables)
figure7 <- ggplot(top_12, aes(x = Lag, y = Max_ACF))+
  geom_point()+
  labs(x = "Lag",
       y = "Max Correlation", 
       title = "Scatter Plot of Top 12 Reddit Indicators by Max Correlation")+
  facet_wrap(~ Variable)
figure7

```

```{r}
source(here("Functions", "05 - covid_data_merging.R"))
```

```{r}
reddit_and_cases1 <- reddit_and_cases %>%
  group_by(MSA_Code) %>%
  mutate(Scaled_DailyCases7 = round(scale(Daily_Cases7), 2),
         Scaled_DailyDeaths7 = round(scale(Daily_Deaths7), 2),
         Scaled_mean_health = round(scale(mean_health), 2),
         Scaled_mean_illness = round(scale(mean_illness), 2))
```


```{r}
figure8 <- ggplot(reddit_and_cases1, aes(x = Date))+
  geom_line(aes(y = Scaled_DailyCases7, color = "Cases"))+
  geom_line(aes(y = Scaled_mean_illness, color = "mean_illness"))+
  facet_wrap(~ City, ncol = 4)+
  scale_color_manual(values = c("Cases" = "blue", "mean_illness" = "orange"))+
  labs(x = "Date",
       y = "Z Score",
       title = "Time Series of mean_illness vs Cases")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels
        axis.text = element_text(size = 10),  # Adjust font size of axis labels
        plot.margin = margin(20, 20, 20, 20))
figure8

```

For each city, the above plot shows the time series of mean_illness vs Covid cases. 
```{r}
figure9 <- ggplot(reddit_and_cases1, aes(x = Date))+
  geom_line(aes(y = Scaled_DailyCases7, color = "Cases"))+
  geom_line(aes(y = Scaled_mean_health, color = "mean_health"))+
  facet_wrap(~ City, nrow = 4)+
  scale_color_manual(values = c("Cases" = "blue", "mean_health" = "red"))+
  labs(x = "Date",
       y = "Z Score",
       title = "Time Series of mean_Health vs Cases")
figure9
```
For each city, the above plot shows the time series of mean_health vs Covid cases. 

##Forecasts

```{r}
source(here("Functions", "06 - forecast_reddit().R"))
```

forecast_reddit() is a file consisting of three functions, with each corresponding to the number of weeks of training data (4 weeks, 8 weeks, cumulative). 
    loads a dataset called reddit_and_cases from a CSV file
    filters the dataset to include only the specified city and calculates rolling averages for the mean_illness column over different time windows (7, 14, and 21 days)
    creates four linear regression models for the city, using different combinations of the mean_illness and rolling averages as predictors for the Daily_Cases7 (7-day average of daily cases) target variable
    creates a new dataset called city_projection_data that includes the future dates for which the forecast will be made, along with the rolling averages of mean_illness
    calculates the forecast for Daily_Cases7 using the appropriate linear regression model and adds the forecasted values, confidence intervals, and R-squared values to the city_projection_data dataset
    If the csv option is set to TRUE, it saves the city_projection_data dataset as a CSV file in the "Results/Projections/<city_name>" directory with a filename that includes the date
    If the csv option is set to FALSE, it returns a list containing the city_projection_data dataset and the summaries of the four linear regression models
    

```{r}
library(cowplot)
```

```{r}
atlanta_nowcast_grid <- plot_grid(atlanta0_28days, atlanta0_56days)
atlanta_nowcast_grid
ggsave("Results/Projections/atlanta_nowcasts.png", atlanta_nowcast_grid, width = 10, height = 6)
```

```{r}
atlanta_7day_grid <- plot_grid(atlanta7_28days, atlanta7_56days)
atlanta_7day_grid
ggsave("Results/Projections/atlanta_7day.png", atlanta_7day_grid, width = 10, height = 6)
```

#Poisson Regression

```{r}
source(here("Functions/07 - graph_reddit_forecasts().R"))
```

```{r}
Cities1 <- c("Atlanta", "Austin","Baltimore", "Boston", "Charlotte", "Chicago", "Columbus","Dallas","Denver","Detroit","Houston","Kansas City","Los Angeles","Minneapolis","Nashville",
            "Orlando", "New York City", "Philadelphia", "Phoenix", "Portland", "Raleigh","Salt Lake City","San Diego", "San Francisco", "Seattle", "St. Louis","Tampa Bay", "Las Vegas", "Washington DC")
Cities2 <- c("Orlando", "Tampa Bay")
```

```{r}
metropolitan_forecasts1 <- list()
for (metro in Cities1) {
  metro_result <- graph_reddit_forecasts(city = metro, start.date = "2020-05-03", end.date = "2022-02-27")
  metropolitan_forecasts1[[metro]] <- metro_result
}
```

```{r}
save(metropolitan_forecasts1, file = "Results/R codes/metropolitan_forecasts1.RData")
```

```{r}
load("Results/R codes/metropolitan_forecasts1.RData")
```

```{r}
library(cowplot)
```

```{r}
# List of cities
Cities1 <- c("Atlanta", "Austin", "Baltimore", "Boston", "Charlotte", "Chicago", "Columbus", "Dallas", "Denver", "Detroit", "Houston", "Kansas City", "Los Angeles", "Minneapolis", "Nashville",
             "Orlando", "New York City", "Philadelphia", "Phoenix", "Portland", "Raleigh", "Salt Lake City", "San Diego", "San Francisco", "Seattle", "St. Louis", "Tampa Bay", "Las Vegas", "Washington DC")

# Function to format city names for variable access
format_city_name <- function(city) {
  if (grepl(" ", city) || grepl("-", city)) {
    return(paste0("`", city, "`"))  # Wrap multi-word city names in backticks
  } else {
    return(city)  # Single-word city names remain unchanged
  }
}

# Function to format city names for filenames
format_filename <- function(city) {
  city_formatted <- gsub(" ", "", city)  # Remove spaces
  city_formatted <- gsub("-", "", city_formatted)  # Remove dashes
  return(city_formatted)
}

# Generate and save plots for each city
for (city in Cities1) {
  city_var <- format_city_name(city)
  city_file <- format_filename(city)
  
  # Create AR plot grid
  ar_plot <- plot_grid(eval(parse(text = paste0("metropolitan_forecasts1$", city_var, "$nowcast_8_ar"))), 
                       eval(parse(text = paste0("metropolitan_forecasts1$", city_var, "$forecast_8_ar"))))
  
  # Create regular plot grid
  plot <- plot_grid(eval(parse(text = paste0("metropolitan_forecasts1$", city_var, "$nowcast_8"))), 
                    eval(parse(text = paste0("metropolitan_forecasts1$", city_var, "$forecast8"))))
  
  # Save AR plot grid
  ggsave(paste0("Results/Projections/ar_", city_file, "_grid.png"), ar_plot, width = 10, height = 6)
  
  # Save regular plot grid
  ggsave(paste0("Results/Projections/", city_file, "_grid.png"), plot, width = 10, height = 6)
}

```

```{r}
files <- list.files("Source Data/Weekly Data") %>% 
  as.vector()
MSA_Codes <- c("C1206", "C1242","C1258", "C1446","C1674", "C1698","C1814",
               "C1910","C1974","C1982","C2642","C2814", "C3108","C3346",
               "C3498","C3538", "C3562", "C3674", "C3798", "C3806", "C3890",
               "C3958","C4162", "C4174", "C4186", "C4266", "C4118","C4530","C2982", "C4790")
Cities <- c("Atlanta", "Austin","Baltimore", "Boston", "Charlotte", "Chicago", "Columbus","Dallas","Denver",
            "Detroit","Houston","Kansas City","Los Angeles","Minneapolis","Nashville","New Orleans",
            "New York City", "Orlando", "Philadelphia", "Phoenix", "Portland", "Raleigh","Salt Lake City",
            "San Diego", "San Francisco", "Seattle", "St. Louis","Tampa Bay","Las Vegas", "Washington DC")
States <- c("Georgia", "Texas", "Maryland", "Massachussetts", "North Carolina", "Illinois", "Ohio", "Texas",
            "Colorado", "Michigan", "Texas", "Missouri", "California", "Minnesota", "Tennessee", "Louisiana",
            "New York", "Florida", "Pennsylvania", "Arizona", "Oregon", "North Carolina", "Utah",
            "California", "California", "Washington", "Missouri", "Florida", "Nevada", "Maryland")
info <- bind_cols(Cities, MSA_Codes) %>% 
  rename(city = `...1`,
         msa_code = `...2`) %>% 
  bind_cols(filename = files, 
            state = States) %>%
  select(city, state, msa_code, filename) %>% 
  rename(City = city, 
         State = state) %>% 
  slice(-16)

```
```{r}
info <- info %>% 
  mutate(CCF_Path = paste0("Results/Graphs/CCF Plots/", City))
```

```{r}
result_list <- list()
for (i in 27:nrow(info)) {
  msa_code <- info$msa_code[i]
  City <- info$City[i]
  State <- info$State[i]
  file <- info$filename[i]
  plot_ccf("Source Data/Weekly Data", filename = file, code = msa_code, city = City, state = State)

}
```


```{r}
result_list$Atlanta
```

```{r}
rank_avg <- read_csv("Results/CSV Files/Average_City_Rank.csv")
table1 <- read_csv("Results/CSV Files/table_of_average_acf_lag.csv")
combined <- read_csv("Results/CSV Files/combined_data.csv")
reddit_and_cases <- read_csv("Results/CSV Files/reddit_and_cases_deaths.csv")
```
```{r}
modified_rc <- reddit_and_cases %>%
  select(-c(MSA_Code, MSA_Title, Cumulative_Cases, Cumulative_Deaths, Weekly_Deaths, mean_function)) %>% 
  na.omit() %>% 
  group_by(week) %>% 
  summarize(Weekly_Cases = sum(Weekly_Cases),
            across(starts_with("mean_"), mean, .names = "{col}"))
  
full_model <- glm(Weekly_Cases~ . - week, family = "poisson", data = modified_rc)
```
```{r}
library(ciTools)
library(cowplot)
modified_rc1 <- modified_rc %>% 
  add_pi(df = ., fit = full_model, names = c("Forecast_Lwr", "Forecast_Upr")) %>% 
  select(week, Forecast_Lwr, pred, Forecast_Upr, everything())

```
```{r}
ggplot(modified_rc1, aes(x = week))+
  geom_line(aes(y = pred), color = "red")+
  geom_ribbon(aes(ymin = Forecast_Lwr, ymax = Forecast_Upr), fill = "yellow", alpha = 0.2)+
  geom_point(aes(y = modified_rc1$Weekly_Cases))+
  scale_y_continuous(labels = scales::comma)+
  scale_x_date(date_breaks = "2 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "Full Model", x = "Date", y = "Cases")
```

```{r}
modified_rc2 <- reddit_and_cases %>% 
  select(week, City, everything()) %>% 
  select(-c(MSA_Code, MSA_Title, mean_function)) %>% 
  na.omit()
```

```{r}
city_selection <- modified_rc2 %>%
  select(-Cumulative_Cases, -Cumulative_Deaths, -Weekly_Deaths)
full_city_model <- glm(Weekly_Cases ~ .- week, family = "poisson", data = city_selection)

modified_city_selection <- city_selection %>% 
  add_pi(df = ., fit = full_city_model, names = c("Forecast_Lwr", "Forecast_Upr")) %>% 
  select(week, Forecast_Lwr, pred, Forecast_Upr, everything())
#facet plot by city

plot <- ggplot(modified_city_selection, aes(x = week))+
  geom_line(aes(y = pred), color = "red")+
  geom_ribbon(aes(ymin = Forecast_Lwr, ymax = Forecast_Upr), fill = "yellow", alpha = 0.2)+
  geom_point(aes(y = modified_city_selection$Weekly_Cases))+
  facet_wrap(~City, scales= "free_y")+
  scale_y_continuous(labels = scales::comma)+
  scale_x_date(date_breaks = "2 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "Full Model for All Cities" , x = "Date", y = "Cases")
save_plot("full_model.png", plot, base_width = 30, base_height = 20)
```


identify most important reddit columns

lag all reddit indicators 1 week, then rerun

```{r}
library(zoo)
modified_rc3 <- reddit_and_cases %>% 
  select(week, City, everything()) %>% 
  select(-c(MSA_Code, MSA_Title, mean_function)) %>%
  mutate(across(7:ncol(.), ~lag(., n = 1), .names = "lag_{col}")) %>% 
  rename(mean_function = mean_function.,
         lag_mean_function = lag_mean_function.) %>% 
  na.omit()
```

```{r}
city_selection1 <- modified_rc3 %>%
  select(-Cumulative_Cases, -Cumulative_Deaths, -Weekly_Deaths) %>% 
  filter(City == "San Francisco") %>% 
  select(-City)
full_city_model1 <- glm(Weekly_Cases ~ .- week, family = "poisson", data = city_selection1)
summary(full_city_model1)
modified_city_selection1 <- city_selection1 %>% 
  add_pi(df = ., fit = full_city_model1, names = c("Forecast_Lwr", "Forecast_Upr")) %>% 
  select(week, Forecast_Lwr, pred, Forecast_Upr, everything())
#facet plot by city

plot <- ggplot(modified_city_selection1, aes(x = week))+
  geom_line(aes(y = pred), color = "red")+
  geom_ribbon(aes(ymin = Forecast_Lwr, ymax = Forecast_Upr), fill = "yellow", alpha = 0.2)+
  geom_point(aes(y = modified_city_selection1$Weekly_Cases))+
  facet_wrap(~City, scales= "free_y")+
  scale_y_continuous(labels = scales::comma)+
  scale_x_date(date_breaks = "2 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "Full Model for All Cities Using All Lagged Indicators" , x = "Date", y = "Cases")
save_plot("full_model1.png", plot, base_width = 30, base_height = 20)
```

```{r}
city_model <- glm(Weekly_Cases~ City + mean_illness + mean_health + mean_Linguistic + mean_function + mean_tentat + lag_mean_illness + lag_mean_health + lag_mean_Linguistic + lag_mean_function + lag_mean_tentat, data = modified_rc3, family = "poisson")
```

```{r}

modified_city_selection2 <- modified_rc3 %>% 
  add_pi(df = ., fit = city_model, names = c("Forecast_Lwr", "Forecast_Upr")) %>% 
  select(week, Forecast_Lwr, pred, Forecast_Upr, everything())
#facet plot by city

plot <- ggplot(modified_city_selection2, aes(x = week))+
  geom_line(aes(y = pred), color = "red")+
  geom_ribbon(aes(ymin = Forecast_Lwr, ymax = Forecast_Upr), fill = "yellow", alpha = 0.2)+
  geom_point(aes(y = Weekly_Cases))+
  facet_wrap(~City, scales= "free_y")+
  scale_y_continuous(labels = scales::comma)+
  scale_x_date(date_breaks = "2 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = "Full Model for All Cities Using All Lagged Indicators" , x = "Date", y = "Cases")
save_plot("city_model.png", plot, base_width = 30, base_height = 20)
```

```{r}
reddit_and_cases <- reddit_and_cases %>% filter(!is.na(City))
cities <- as.vector(unique(reddit_and_cases$City))
```

```{r}
for (city in cities) {
  selection <- reddit_and_cases %>% 
    filter(City == city) %>% 
    select(week, City, everything()) %>% 
    select(-c(MSA_Code, MSA_Title, mean_function, City)) %>%
    mutate(across(7:ncol(.), ~lag(., n = 1), .names = "lag_{col}")) %>% 
    rename(mean_function = mean_function.,
           lag_mean_function = lag_mean_function.) %>% 
    na.omit()
  model <- glm(Weekly_Cases ~ ., family = "poisson", data = selection)
  modified_selection <- selection %>% 
    add_pi(df = ., fit = model, names = c("Forecast_Lwr", "Forecast_Upr")) %>% 
    select(week, Forecast_Lwr, pred, Forecast_Upr, everything())
  plot <- ggplot(modified_city_selection2, aes(x = week))+
    geom_line(aes(y = pred), color = "red")+
    geom_ribbon(aes(ymin = Forecast_Lwr, ymax = Forecast_Upr), fill = "yellow", alpha = 0.2)+
    geom_point(aes(y = Weekly_Cases))+
    facet_wrap(~City, scales= "free_y")+
    scale_y_continuous(labels = scales::comma)+
    scale_x_date(date_breaks = "2 months")+
    theme(axis.text.x = element_text(angle = 45, hjust = 1))+
    labs(title = paste("Full Model for", city, "Using All Lagged Indicators"), x = "Date", y = "Cases")
  file_name <- paste0("Results/Projections/2024_06_30/", city, "_forecast")
  ggsave(filename = file_name, plot = plot)
}
```

```{r}
city = "Atlanta"
selection <- reddit_and_cases %>% 
  #select(week, City, everything()) #%>%
  filter(City == city) %>% 
  mutate(across(6:ncol(.), ~lag(., n = 1), .names = "lag_{col}")) %>%
  select(-c(City, MSA_Code, MSA_Title, mean_function, lag_mean_function)) %>%
  filter(complete.cases(.)) %>% 
  rename(mean_function = mean_function.,
         lag_mean_function = lag_mean_function.)
selection1 <- selection %>%
  select(-c(Cumulative_Cases, Cumulative_Deaths, Weekly_Deaths, lag_City)) %>% 
  filter(complete.cases(.))
full_city_model1 <- glm(Weekly_Cases ~ .-week, family = "poisson", data = selection1)
summary(full_city_model1)
```

```{r}
city = "Atlanta"
selection <- reddit_and_cases %>% 
  #select(week, City, everything()) #%>%
  filter(City == city) %>% 
  mutate(across(6:ncol(.), ~lag(., n = 1), .names = "lag_{col}")) %>%
  select(-c(City, MSA_Code, MSA_Title, mean_function, lag_mean_function)) %>%
  filter(complete.cases(.)) %>% 
  rename(mean_function = mean_function.,
         lag_mean_function = lag_mean_function.)
selection1 <- selection %>%
  select(-c(Cumulative_Cases, Cumulative_Deaths, Weekly_Deaths, lag_City)) %>% 
  filter(complete.cases(.))
full_city_model1 <- glm(Weekly_Cases ~ mean_Analytic + lag_mean_differ + mean_Clout + lag_mean_illness + mean_Authentic + mean_Race_Related + lag_mean_quantity, family = "poisson", data = selection1)
```

```{r}
modified_selection <- selection %>% 
  add_pi(df = ., fit = full_city_model1, names = c("Forecast_Lwr", "Forecast_Upr")) %>% 
  select(week, Forecast_Lwr, pred, Forecast_Upr, everything())
plot <- ggplot(modified_selection, aes(x = week))+
  geom_line(aes(y = pred), color = "red")+
  geom_ribbon(aes(ymin = Forecast_Lwr, ymax = Forecast_Upr), fill = "yellow", alpha = 0.2)+
  geom_line(aes(y = Weekly_Cases), color = "blue")+
  scale_y_continuous(labels = scales::comma)+
  scale_x_date(date_breaks = "2 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
plot
```
```{r}
cities <- as.vector(unique(reddit_and_cases$City)) %>% na.omit() 
cities <- cities[cities != "New Orleans"]
```

```{r}
for (city in cities) {
  selection <- reddit_and_cases %>% 
    filter(City == city) %>% 
    select(where(~ !all(is.na(.)))) %>% 
    mutate(across(starts_with("mean_"), ~lag(., n = 1), .names = "lag_{col}")) %>% 
    na.omit()
      
  
  selection1 <- selection %>%
    select(-c(Cumulative_Cases, Cumulative_Deaths, Weekly_Deaths)) %>% 
    filter(complete.cases(.))
  
  prcomp <- prcomp(selection1 %>% select(starts_with("mean_")), scale = T)
  prcomp$rotation <- -1 * prcomp$rotation
  rotation <- data.frame(prcomp$rotation)
  rotation <- rownames_to_column(rotation, var = "Variable")
  
  r2 <- data.frame(R2 = (prcomp$sdev)^2 / sum((prcomp$sdev)^2)) %>% 
    mutate(Cumulative_R2 = cumsum(R2),
         PC = seq(1, nrow(.), by = 1)) %>% 
    select(PC, R2, Cumulative_R2)
  rotation1 <- rotation %>%
    summarize(across(starts_with("PC"),
                     list(variable = ~ Variable[which.max(.)]), .names = "{.col}_{.fn}")) %>%
    t() %>% 
    as.data.frame() %>% 
    rename(Variable = V1) %>% 
    bind_cols(r2)
  
  rotation1 <- rownames_to_column(rotation1, var = "rowname")
  rotation1 <- rotation1 %>% 
    select(-rowname) %>% 
    select(PC, everything()) %>% 
    mutate(R2 = round(R2, 3), 
           Cumulative_R2 = round(Cumulative_R2, 3)) %>% 
    filter(Cumulative_R2 <= 0.85)
  
  variables <- as.vector(rotation1$Variable)
  additional_column <- c("Weekly_Cases", "week")
  columns_to_select <- c(variables, additional_column)
  
  selection2 <- selection1 %>% 
    select(all_of(columns_to_select)) %>% 
    select(Weekly_Cases, everything())
  
  model <- glm(Weekly_Cases~., data = selection2, family = "poisson")
  
  modified_selection <- selection2 %>% 
    add_pi(df = ., model, names = c("Forecast_Lwr", "Forecast_Upr")) %>% 
    select(week, Forecast_Lwr, pred, Forecast_Upr, everything())
  fwrite(modified_selection, paste0("Results/Projections/2024_06_30/", city, "_table.csv"))
  
  plot <- ggplot(modified_selection, aes(x = week))+
    geom_line(aes(y = pred), color = "red")+
    geom_ribbon(aes(ymin = Forecast_Lwr, ymax = Forecast_Upr), fill = "yellow", alpha = 0.2)+
    geom_point(aes(y = Weekly_Cases))+
    scale_y_continuous(labels = scales::comma)+
    scale_x_date(date_breaks = "2 months")+
    theme(axis.text.x = element_text(angle = 45, hjust = 1))+
    labs(title = paste("Full Model for", city, "Using 7 Indicators"), x = "Date", y = "Cases")

  file_name <- paste0("Results/Projections/2024_06_30/", city, "_forecast.png")
  ggsave(filename = file_name, plot = plot, width = 8, height = 8)
  cat("finished graphing", city)
}
```

```{r}
as.data.frame(cities)
```
```{r}
city = "New Orleans"
selection <- reddit_and_cases %>% 
  filter(City == city) %>% 
  select(week, City, everything()) %>% 
  select(-c(MSA_Code, MSA_Title, mean_function, City)) %>%
  mutate(across(7:ncol(.), ~lag(., n = 1), .names = "lag_{col}")) %>% 
  rename(mean_function = mean_function.,
         lag_mean_function = lag_mean_function.) %>%
  select(-lag_mean_function) #%>% 

model <- glm(Weekly_Cases ~ mean_Analytic + lag_mean_differ + mean_Clout +
               lag_mean_illness + mean_Authentic + mean_Race_Related + lag_mean_quantity,
             family = "poisson", data = selection)
  
modified_selection <- selection %>% 
  add_pi(df = ., model, names = c("Forecast_Lwr", "Forecast_Upr")) %>% 
  select(week, Forecast_Lwr, pred, Forecast_Upr, everything())
plot <- ggplot(modified_selection, aes(x = week))+
  geom_line(aes(y = pred), color = "red")+
  geom_ribbon(aes(ymin = Forecast_Lwr, ymax = Forecast_Upr), fill = "yellow", alpha = 0.2)+
  geom_point(aes(y = Weekly_Cases))+
  scale_y_continuous(labels = scales::comma)+
  scale_x_date(date_breaks = "2 months")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = paste("Full Model for", city, "Using 7 Indicators"), x = "Date", y = "Cases")
file_name <- paste0("Results/Projections/2024_06_30/", city, "_forecast.png")
ggsave(filename = file_name, plot = plot, width = 8, height = 8)
```

nowcast full model

```{r}
library(cowplot)
for (city in cities) {
  full_nowcast <- reddit_and_cases %>% 
    filter(City == city) %>% 
    select(where(~ !all(is.na(.)))) %>% 
    na.omit() %>% 
    select(week, Weekly_Cases, starts_with("mean_"))
  
  no_lag_model <- glm(Weekly_Cases~. - week, family = "poisson", data = full_nowcast)
  
  full_nowcast <- full_nowcast %>% 
    add_pi(df = ., no_lag_model, names = c("Forecast_Lwr", "Forecast_Upr")) %>% 
    select(week, Forecast_Lwr, pred, Forecast_Upr, everything())
  
  p <- ggplot(full_nowcast, aes(x = week))+
    geom_line(aes(y = pred), color = "red")+
    geom_ribbon(aes(ymin = Forecast_Lwr, ymax = Forecast_Upr), fill = "yellow", alpha = 0.2)+
    geom_point(aes(y = Weekly_Cases))+
    scale_y_continuous(labels = scales::comma)+
    scale_x_date(date_breaks = "2 months")+
    theme(axis.text.x = element_text(angle = 45, hjust = 1))+
    labs(title = paste("Full Nowcast Model for", city), x = "Date", y = "Cases")
  
  file_name <- paste0("Results/Graphs/Forecasts/2024_07_03/nowcasts_", city, ".png")
  save_plot(filename = file_name, plot = p)
}
```

```{r}
for (city in cities) {
  full_forecast <- reddit_and_cases %>% 
    filter(City == city) %>% 
    select(week, City, everything()) %>% 
    select(where(~ !all(is.na(.)))) %>% 
    mutate(across(starts_with("mean_"), ~lag(., n = 1), .names = "lag_{col}")) %>% 
    na.omit() %>% 
    select(week, Weekly_Cases, starts_with("lag_mean_"))
  
  lag_model <- glm(Weekly_Cases~. - week, family = "poisson", data = full_forecast)
  
  full_forecast <- full_forecast %>% 
    add_pi(df = ., lag_model, names = c("Forecast_Lwr", "Forecast_Upr")) %>% 
    select(week, Forecast_Lwr, pred, Forecast_Upr, everything())
  
  p <- ggplot(full_forecast, aes(x = week))+
    geom_line(aes(y = pred), color = "red")+
    geom_ribbon(aes(ymin = Forecast_Lwr, ymax = Forecast_Upr), fill = "yellow", alpha = 0.2)+
    geom_point(aes(y = Weekly_Cases))+
    scale_y_continuous(labels = scales::comma)+
    scale_x_date(date_breaks = "2 months")+
    theme(axis.text.x = element_text(angle = 45, hjust = 1))+
    labs(title = paste("Full Forecast Model for", city), x = "Date", y = "Cases")
  
  file_name <- paste0("Results/Graphs/Forecasts/2024_07_03/forecasts_", city, ".png")
  save_plot(filename = file_name, plot = p)
}
```

